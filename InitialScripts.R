data =  scan(what="character","tweets_15m.txt",sep = "\n",allowEscapes=FALSE)
data = gsub("\t"," ",data)
no_query = 1000
words.list = strsplit(data[-(1:no_query)], "\\W+", perl=TRUE) # Consider only the tweets from the database
words.vector = unlist(words.list)
term_frequency = table(words.vector)
sorted.words = sort(term_frequency,decreasing=TRUE)
save(sorted.words,file = "sorted.words.Rdata")
dict_len = length(sorted.words)
save(dict_len,file = "dict_len.Rdata")
n_t = table(term_frequency)
save(n_t,file = "n_t.Rdata")
data.list = strsplit(data, "\\W+", perl=TRUE)
words = unlist(data.list)
Sys.time()
tweet_index = relist(match(words, sorted_words), data.list)
save(tweet_index,file = "tweet_index.Rdata")
Sys.time()
y = lapply(tweet_index,function(x) stl_sort(x))
save(y,file = "tweet_index_sorted.Rdata")